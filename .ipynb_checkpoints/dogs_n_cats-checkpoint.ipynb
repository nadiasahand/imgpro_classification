{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef25e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b2a25",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e08b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db427e06",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd7493d9",
   "metadata": {},
   "source": [
    "#### flow from directory function\n",
    "Requires a specific folder structure for dataset. Different classes should be placed in different sub-folders but inside the same parent folder. Downloading kaggle's cats and dog dataset using this [link](https://www.microsoft.com/en-us/download/details.aspx?id=54765) provides the following dataset structure:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1adfb8f",
   "metadata": {},
   "source": [
    "In order to use flow_from_directory method, we need to change it to the following:\n",
    "\n",
    "\n",
    "    \n",
    "The following script automates the process. Download the dataset and put the \"PetsImage\" in the project root.\n",
    "\n",
    "** NOTE ** Choose one of the methods flow_from_directory or flow_from_dataframe; meaning run one of the two blocks blow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc007c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from math import floor\n",
    "\n",
    "# creating required directories\n",
    "required_dirs = ['Pets','./Pets/train','./Pets/test','./Pets/validation','./Pets/train/Cat','./Pets/test/Cat',\n",
    "                 './Pets/validation/Cat', './Pets/train/Dog','./Pets/test/Dog','./Pets/validation/Dog']\n",
    "for directory in required_dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "\n",
    "def split_train_validation_test(dataset_path, class_name):\n",
    "    '''\n",
    "    gets dataset path for each class and the class name,\n",
    "    splits dataset classes into 3 subsets: train, validation, test\n",
    "        - test dataset consists of 20% of whole data. assuming 100 images for whole class, 20 images will go to test subset.\n",
    "        - validation dataset consists of 20% of remaining data, therefore 16 images will go to validation subset.\n",
    "        - train dataset consists of the remaing data. (64 images in our prevision assumption.)\n",
    "    '''\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if not file.endswith('.jpg'):\n",
    "            os.remove(dataset_path + file)\n",
    "\n",
    "    for i in range(0,floor(0.2 * len(os.listdir(dataset_path)))):\n",
    "        test_file = random.choice(os.listdir(dataset_path))\n",
    "        shutil.copy(dataset_path+test_file, './Pets/test/' + class_name+'/'+test_file)\n",
    "        os.remove(dataset_path+test_file)\n",
    "\n",
    "    for j in range(0,floor(0.2 * len(os.listdir(dataset_path)))):\n",
    "        v_file = random.choice(os.listdir(dataset_path))\n",
    "        shutil.copy(dataset_path+v_file, './Pets/validation/' + class_name+'/'+v_file)\n",
    "        os.remove(dataset_path+v_file)\n",
    "    \n",
    "    for file in os.listdir(dataset_path):\n",
    "        shutil.copy(dataset_path+file, './Pets/train/' + class_name+'/'+file)\n",
    "        os.remove(dataset_path+file)\n",
    "        \n",
    "\n",
    "# spliting data, since we only have two class:        \n",
    "split_train_validation_test(\"./PetImages/Cat/\",'Cat')\n",
    "split_train_validation_test(\"./PetImages/Dog/\",'Dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e8ee4",
   "metadata": {},
   "source": [
    "#### flow from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# creating dataframe\n",
    "file_names=[]\n",
    "category=[]\n",
    "cat_path ='./PetImages/Cat/'\n",
    "dog_path ='./PetImages/Dog/'\n",
    "for file in os.listdir(cat_path):\n",
    "    if not file.endswith('.jpg'):\n",
    "        os.remove(cat_path + file)\n",
    "    else:\n",
    "        file_names.append('Cat/'+str(file))\n",
    "        category.append(\"0\")\n",
    "    \n",
    "for file in os.listdir(dog_path):\n",
    "    if not file.endswith('.jpg'):\n",
    "        os.remove(dog_path + file)\n",
    "    else:\n",
    "        file_names.append('Dog/'+str(file))\n",
    "        category.append(\"1\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'filename': file_names,\n",
    "        'category': category\n",
    "    })\n",
    "\n",
    "\n",
    "# spliting test, validation, and train datasets\n",
    "train_x, test_x, train_y, test_y = train_test_split(df['filename'], df['category'], \n",
    "                                                  test_size = 0.2)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, \n",
    "                                                  test_size = 0.2)\n",
    "\n",
    "# creating test, validation, and train dataframes\n",
    "df_train = pd.DataFrame({\n",
    "        'filename': train_x,\n",
    "        'category': train_y\n",
    "    })\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "        'filename': val_x,\n",
    "        'category': val_y\n",
    "    })\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "        'filename': test_x,\n",
    "        'category': test_y\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae0924",
   "metadata": {},
   "source": [
    "#### create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e5fd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15998 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#Training Set\n",
    "train_set = train_datagen.flow_from_directory('./Pets/train/',\n",
    "                                             target_size=(128,128),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='binary')\n",
    "#Validation Set\n",
    "validation_set = test_datagen.flow_from_directory('./Pets/validation/',\n",
    "                                           target_size=(128,128),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode='binary',\n",
    "                                           shuffle=False)\n",
    "\n",
    "#Test Set\n",
    "test_set = test_datagen.flow_from_directory('./Pets/test/',\n",
    "                                           target_size=(128,128),\n",
    "                                           class_mode=\"binary\",\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d3994",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c760fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32,(3,3),input_shape=(128,128,3),activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "classifier.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "classifier.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dense(units=1,activation='sigmoid'))\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "classifier.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff2ac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 320s 764ms/step - loss: 0.6340 - accuracy: 0.6239 - val_loss: 0.6493 - val_accuracy: 0.6625\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 84s 209ms/step - loss: 0.5207 - accuracy: 0.7400 - val_loss: 0.3559 - val_accuracy: 0.8562\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 62s 155ms/step - loss: 0.4687 - accuracy: 0.7772 - val_loss: 0.3859 - val_accuracy: 0.8438\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 0.4342 - accuracy: 0.7977 - val_loss: 0.3872 - val_accuracy: 0.8344\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.4096 - accuracy: 0.8110 - val_loss: 0.3915 - val_accuracy: 0.8328\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.3846 - accuracy: 0.8251 - val_loss: 0.3720 - val_accuracy: 0.8250\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.3631 - accuracy: 0.8374 - val_loss: 0.4121 - val_accuracy: 0.8141\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.3516 - accuracy: 0.8406 - val_loss: 0.3225 - val_accuracy: 0.8687\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.3323 - accuracy: 0.8543 - val_loss: 0.7080 - val_accuracy: 0.6891\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.3211 - accuracy: 0.8604 - val_loss: 0.5790 - val_accuracy: 0.7297\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.3080 - accuracy: 0.8662 - val_loss: 0.2348 - val_accuracy: 0.9203\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.2793 - accuracy: 0.8790 - val_loss: 0.3936 - val_accuracy: 0.8375\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.2708 - accuracy: 0.8879 - val_loss: 0.3972 - val_accuracy: 0.8469\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.2624 - accuracy: 0.8877 - val_loss: 0.5986 - val_accuracy: 0.7703\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.2453 - accuracy: 0.8986 - val_loss: 0.4322 - val_accuracy: 0.8281\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.2310 - accuracy: 0.9033 - val_loss: 0.3335 - val_accuracy: 0.8719\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 242s 607ms/step - loss: 0.2257 - accuracy: 0.9051 - val_loss: 0.5744 - val_accuracy: 0.7797\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 97s 242ms/step - loss: 0.2161 - accuracy: 0.9108 - val_loss: 0.3398 - val_accuracy: 0.8781\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 63s 157ms/step - loss: 0.2056 - accuracy: 0.9158 - val_loss: 0.4957 - val_accuracy: 0.8219\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 59s 146ms/step - loss: 0.1965 - accuracy: 0.9204 - val_loss: 0.4135 - val_accuracy: 0.8375\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.1792 - accuracy: 0.9283 - val_loss: 0.4821 - val_accuracy: 0.8219\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.1730 - accuracy: 0.9304 - val_loss: 0.4639 - val_accuracy: 0.8375\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.1636 - accuracy: 0.9329 - val_loss: 0.3972 - val_accuracy: 0.8531\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1569 - accuracy: 0.9362 - val_loss: 0.3715 - val_accuracy: 0.8781\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1529 - accuracy: 0.9394 - val_loss: 0.4615 - val_accuracy: 0.8359\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1393 - accuracy: 0.9441 - val_loss: 0.4155 - val_accuracy: 0.8625\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1335 - accuracy: 0.9476 - val_loss: 0.4522 - val_accuracy: 0.8562\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1315 - accuracy: 0.9501 - val_loss: 0.4978 - val_accuracy: 0.8328\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1258 - accuracy: 0.9523 - val_loss: 0.4641 - val_accuracy: 0.8438\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1225 - accuracy: 0.9513 - val_loss: 0.4329 - val_accuracy: 0.8594\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1162 - accuracy: 0.9546 - val_loss: 0.3499 - val_accuracy: 0.9000\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.1069 - accuracy: 0.9582 - val_loss: 0.5864 - val_accuracy: 0.8375\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.1075 - accuracy: 0.9561 - val_loss: 0.6929 - val_accuracy: 0.7859\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0988 - accuracy: 0.9614 - val_loss: 0.6252 - val_accuracy: 0.8391\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0984 - accuracy: 0.9630 - val_loss: 0.6411 - val_accuracy: 0.8266\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0952 - accuracy: 0.9640 - val_loss: 0.8323 - val_accuracy: 0.8109\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0962 - accuracy: 0.9643 - val_loss: 0.5304 - val_accuracy: 0.8562\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0892 - accuracy: 0.9665 - val_loss: 0.6989 - val_accuracy: 0.8297\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0848 - accuracy: 0.9677 - val_loss: 0.7260 - val_accuracy: 0.8188\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 53s 131ms/step - loss: 0.0784 - accuracy: 0.9717 - val_loss: 0.6326 - val_accuracy: 0.8406\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0720 - accuracy: 0.9720 - val_loss: 0.4681 - val_accuracy: 0.8594\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0798 - accuracy: 0.9706 - val_loss: 0.3922 - val_accuracy: 0.8984\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0739 - accuracy: 0.9721 - val_loss: 0.5632 - val_accuracy: 0.8641\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0716 - accuracy: 0.9737 - val_loss: 0.6429 - val_accuracy: 0.8469\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0728 - accuracy: 0.9741 - val_loss: 0.7091 - val_accuracy: 0.8344\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0665 - accuracy: 0.9744 - val_loss: 0.6159 - val_accuracy: 0.8422\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0623 - accuracy: 0.9760 - val_loss: 0.8835 - val_accuracy: 0.8031\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0606 - accuracy: 0.9771 - val_loss: 0.9569 - val_accuracy: 0.8109\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 0.0675 - accuracy: 0.9755 - val_loss: 0.6630 - val_accuracy: 0.8422\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0621 - accuracy: 0.9787 - val_loss: 1.3450 - val_accuracy: 0.7516\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0703 - accuracy: 0.9748 - val_loss: 0.5614 - val_accuracy: 0.8531\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.6655 - val_accuracy: 0.8719\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0649 - accuracy: 0.9762 - val_loss: 0.7952 - val_accuracy: 0.8266\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0545 - accuracy: 0.9802 - val_loss: 0.6768 - val_accuracy: 0.8578\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0535 - accuracy: 0.9801 - val_loss: 0.6961 - val_accuracy: 0.8344\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0564 - accuracy: 0.9789 - val_loss: 0.9563 - val_accuracy: 0.7609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0611 - accuracy: 0.9778 - val_loss: 0.8558 - val_accuracy: 0.8109\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0531 - accuracy: 0.9811 - val_loss: 0.9619 - val_accuracy: 0.7953\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0471 - accuracy: 0.9835 - val_loss: 0.8690 - val_accuracy: 0.8141\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0469 - accuracy: 0.9834 - val_loss: 0.9423 - val_accuracy: 0.8219\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0596 - accuracy: 0.9787 - val_loss: 0.7219 - val_accuracy: 0.8422\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0516 - accuracy: 0.9809 - val_loss: 0.7861 - val_accuracy: 0.8453\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 0.7783 - val_accuracy: 0.8266\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.6478 - val_accuracy: 0.8594\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0436 - accuracy: 0.9827 - val_loss: 0.5506 - val_accuracy: 0.8906\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.8602 - val_accuracy: 0.8359\n",
      "Epoch 67/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0431 - accuracy: 0.9859 - val_loss: 0.6470 - val_accuracy: 0.8609\n",
      "Epoch 68/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0368 - accuracy: 0.9859 - val_loss: 1.3040 - val_accuracy: 0.7922\n",
      "Epoch 69/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0479 - accuracy: 0.9829 - val_loss: 0.8924 - val_accuracy: 0.7875\n",
      "Epoch 70/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0463 - accuracy: 0.9827 - val_loss: 1.0127 - val_accuracy: 0.8234\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.9994 - val_accuracy: 0.8125\n",
      "Epoch 72/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 1.1434 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 0.5376 - val_accuracy: 0.8875\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0391 - accuracy: 0.9856 - val_loss: 0.8823 - val_accuracy: 0.8469\n",
      "Epoch 75/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0456 - accuracy: 0.9843 - val_loss: 0.8243 - val_accuracy: 0.8438\n",
      "Epoch 76/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 1.0955 - val_accuracy: 0.8000\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.6770 - val_accuracy: 0.8672\n",
      "Epoch 78/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.8096 - val_accuracy: 0.8484\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.7004 - val_accuracy: 0.8672\n",
      "Epoch 80/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0453 - accuracy: 0.9837 - val_loss: 0.7468 - val_accuracy: 0.8438\n",
      "Epoch 81/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0377 - accuracy: 0.9858 - val_loss: 1.0934 - val_accuracy: 0.8094\n",
      "Epoch 82/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 0.8784 - val_accuracy: 0.8391\n",
      "Epoch 83/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 1.2423 - val_accuracy: 0.8016\n",
      "Epoch 84/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0320 - accuracy: 0.9879 - val_loss: 1.0076 - val_accuracy: 0.8203\n",
      "Epoch 85/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.7525 - val_accuracy: 0.8672\n",
      "Epoch 86/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0293 - accuracy: 0.9895 - val_loss: 0.9672 - val_accuracy: 0.8453\n",
      "Epoch 87/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.9794 - val_accuracy: 0.8500\n",
      "Epoch 88/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.8007 - val_accuracy: 0.8609\n",
      "Epoch 89/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0428 - accuracy: 0.9846 - val_loss: 1.2665 - val_accuracy: 0.8062\n",
      "Epoch 90/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.8826 - val_accuracy: 0.8516\n",
      "Epoch 91/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0356 - accuracy: 0.9874 - val_loss: 1.0115 - val_accuracy: 0.8359\n",
      "Epoch 92/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.8434 - val_accuracy: 0.8484\n",
      "Epoch 93/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 1.1919 - val_accuracy: 0.8250\n",
      "Epoch 94/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0376 - accuracy: 0.9868 - val_loss: 0.9954 - val_accuracy: 0.8547\n",
      "Epoch 95/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 1.0971 - val_accuracy: 0.8219\n",
      "Epoch 96/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 0.8405 - val_accuracy: 0.8672\n",
      "Epoch 97/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 1.2145 - val_accuracy: 0.8078\n",
      "Epoch 98/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.9271 - val_accuracy: 0.8453\n",
      "Epoch 99/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 1.4732 - val_accuracy: 0.7812\n",
      "Epoch 100/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 1.1678 - val_accuracy: 0.8219\n",
      "Epoch 101/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0290 - accuracy: 0.9892 - val_loss: 1.1359 - val_accuracy: 0.8297\n",
      "Epoch 102/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0324 - accuracy: 0.9880 - val_loss: 0.6244 - val_accuracy: 0.8969\n",
      "Epoch 103/200\n",
      "400/400 [==============================] - 56s 139ms/step - loss: 0.0255 - accuracy: 0.9903 - val_loss: 1.0710 - val_accuracy: 0.8266\n",
      "Epoch 104/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 1.2818 - val_accuracy: 0.8141\n",
      "Epoch 105/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0279 - accuracy: 0.9898 - val_loss: 1.1050 - val_accuracy: 0.8438\n",
      "Epoch 106/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0292 - accuracy: 0.9901 - val_loss: 0.9396 - val_accuracy: 0.8469\n",
      "Epoch 107/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 1.1420 - val_accuracy: 0.8375\n",
      "Epoch 108/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 1.2056 - val_accuracy: 0.7953\n",
      "Epoch 109/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.9508 - val_accuracy: 0.8359\n",
      "Epoch 110/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.9238 - val_accuracy: 0.8438\n",
      "Epoch 111/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.8773 - val_accuracy: 0.8562\n",
      "Epoch 112/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 1.1362 - val_accuracy: 0.8141\n",
      "Epoch 113/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 1.0185 - val_accuracy: 0.8422\n",
      "Epoch 114/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 0.9674 - val_accuracy: 0.8281\n",
      "Epoch 115/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.8953 - val_accuracy: 0.8656\n",
      "Epoch 116/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 1.2111 - val_accuracy: 0.8484\n",
      "Epoch 117/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0249 - accuracy: 0.9908 - val_loss: 1.0569 - val_accuracy: 0.8188\n",
      "Epoch 118/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 1.0891 - val_accuracy: 0.8562\n",
      "Epoch 119/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 1.1433 - val_accuracy: 0.8391\n",
      "Epoch 120/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 0.5823 - val_accuracy: 0.8969\n",
      "Epoch 121/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 0.9801 - val_accuracy: 0.8656\n",
      "Epoch 122/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.9219 - val_accuracy: 0.8625\n",
      "Epoch 123/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0305 - accuracy: 0.9894 - val_loss: 1.2766 - val_accuracy: 0.8406\n",
      "Epoch 124/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 1.2541 - val_accuracy: 0.8313\n",
      "Epoch 125/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 0.9652 - val_accuracy: 0.8516\n",
      "Epoch 126/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 1.1233 - val_accuracy: 0.8484\n",
      "Epoch 127/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 1.2372 - val_accuracy: 0.8266\n",
      "Epoch 128/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.3826 - val_accuracy: 0.8109\n",
      "Epoch 129/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 1.2090 - val_accuracy: 0.8328\n",
      "Epoch 130/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 1.0385 - val_accuracy: 0.8438\n",
      "Epoch 131/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0271 - accuracy: 0.9910 - val_loss: 1.1545 - val_accuracy: 0.8281\n",
      "Epoch 132/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 1.0421 - val_accuracy: 0.8594\n",
      "Epoch 133/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 1.2722 - val_accuracy: 0.8313\n",
      "Epoch 134/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 1.5638 - val_accuracy: 0.7828\n",
      "Epoch 135/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 1.4585 - val_accuracy: 0.8156\n",
      "Epoch 136/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0228 - accuracy: 0.9917 - val_loss: 0.9841 - val_accuracy: 0.8562\n",
      "Epoch 137/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 1.8852 - val_accuracy: 0.7750\n",
      "Epoch 138/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 1.0837 - val_accuracy: 0.8484\n",
      "Epoch 139/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 1.0721 - val_accuracy: 0.8734\n",
      "Epoch 140/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 1.0689 - val_accuracy: 0.8781\n",
      "Epoch 141/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 1.1505 - val_accuracy: 0.8156\n",
      "Epoch 142/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 1.6907 - val_accuracy: 0.7875\n",
      "Epoch 143/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 1.1579 - val_accuracy: 0.8328\n",
      "Epoch 144/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.9966 - val_accuracy: 0.8687\n",
      "Epoch 145/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 1.3961 - val_accuracy: 0.8188\n",
      "Epoch 146/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.8676 - val_accuracy: 0.8641\n",
      "Epoch 147/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 1.1182 - val_accuracy: 0.8844\n",
      "Epoch 148/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0289 - accuracy: 0.9902 - val_loss: 1.1976 - val_accuracy: 0.8422\n",
      "Epoch 149/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 1.1929 - val_accuracy: 0.8313\n",
      "Epoch 150/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 1.0504 - val_accuracy: 0.8578\n",
      "Epoch 151/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 1.0389 - val_accuracy: 0.8531\n",
      "Epoch 152/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.6652 - val_accuracy: 0.9000\n",
      "Epoch 153/200\n",
      "400/400 [==============================] - 56s 139ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 1.2047 - val_accuracy: 0.8438\n",
      "Epoch 154/200\n",
      "400/400 [==============================] - 58s 146ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 1.2693 - val_accuracy: 0.8359\n",
      "Epoch 155/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 1.1430 - val_accuracy: 0.8641\n",
      "Epoch 156/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 1.2084 - val_accuracy: 0.8531\n",
      "Epoch 157/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 1.2215 - val_accuracy: 0.8406\n",
      "Epoch 158/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 1.3139 - val_accuracy: 0.8281\n",
      "Epoch 159/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 1.0535 - val_accuracy: 0.8531\n",
      "Epoch 160/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 1.5144 - val_accuracy: 0.7875\n",
      "Epoch 161/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 1.1453 - val_accuracy: 0.8438\n",
      "Epoch 162/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.8975 - val_accuracy: 0.8625\n",
      "Epoch 163/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.9563 - val_accuracy: 0.8531\n",
      "Epoch 164/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 1.2586 - val_accuracy: 0.8156\n",
      "Epoch 165/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 1.5431 - val_accuracy: 0.7937\n",
      "Epoch 166/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 1.6941 - val_accuracy: 0.7906\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 1.8871 - val_accuracy: 0.7781\n",
      "Epoch 168/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 1.0821 - val_accuracy: 0.8594\n",
      "Epoch 169/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 1.5055 - val_accuracy: 0.8109\n",
      "Epoch 170/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 1.3009 - val_accuracy: 0.8266\n",
      "Epoch 171/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 1.4605 - val_accuracy: 0.8203\n",
      "Epoch 172/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 1.3301 - val_accuracy: 0.8141\n",
      "Epoch 173/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0226 - accuracy: 0.9918 - val_loss: 1.3971 - val_accuracy: 0.8125\n",
      "Epoch 174/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.9884 - val_accuracy: 0.8562\n",
      "Epoch 175/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0237 - accuracy: 0.9935 - val_loss: 0.9282 - val_accuracy: 0.8734\n",
      "Epoch 176/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 1.1242 - val_accuracy: 0.8406\n",
      "Epoch 177/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 1.1205 - val_accuracy: 0.8188\n",
      "Epoch 178/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 1.4055 - val_accuracy: 0.8281\n",
      "Epoch 179/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 1.1496 - val_accuracy: 0.8469\n",
      "Epoch 180/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 1.3605 - val_accuracy: 0.8219\n",
      "Epoch 181/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 1.1744 - val_accuracy: 0.8297\n",
      "Epoch 182/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0138 - accuracy: 0.9944 - val_loss: 1.8238 - val_accuracy: 0.7984\n",
      "Epoch 183/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 1.7323 - val_accuracy: 0.7812\n",
      "Epoch 184/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 1.3389 - val_accuracy: 0.8250\n",
      "Epoch 185/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 1.0892 - val_accuracy: 0.8562\n",
      "Epoch 186/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 1.1980 - val_accuracy: 0.8406\n",
      "Epoch 187/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 1.3880 - val_accuracy: 0.8250\n",
      "Epoch 188/200\n",
      "400/400 [==============================] - 56s 139ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 1.2284 - val_accuracy: 0.8469\n",
      "Epoch 189/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 1.2379 - val_accuracy: 0.8516\n",
      "Epoch 190/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 1.0289 - val_accuracy: 0.8703\n",
      "Epoch 191/200\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 1.6016 - val_accuracy: 0.8109\n",
      "Epoch 192/200\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 1.1285 - val_accuracy: 0.8469\n",
      "Epoch 193/200\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 1.0915 - val_accuracy: 0.8547\n",
      "Epoch 194/200\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 1.5488 - val_accuracy: 0.8188\n",
      "Epoch 195/200\n",
      "400/400 [==============================] - 52s 130ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 1.0865 - val_accuracy: 0.8625\n",
      "Epoch 196/200\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 1.4983 - val_accuracy: 0.8047\n",
      "Epoch 197/200\n",
      "400/400 [==============================] - 52s 129ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 1.3987 - val_accuracy: 0.8203\n",
      "Epoch 198/200\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 1.4545 - val_accuracy: 0.8141\n",
      "Epoch 199/200\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0165 - accuracy: 0.9934 - val_loss: 1.3763 - val_accuracy: 0.8266\n",
      "Epoch 200/200\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.3195 - val_accuracy: 0.8422\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Training\n",
    "history = classifier.fit(train_set,\n",
    "                        steps_per_epoch=400, \n",
    "                        epochs = 200,\n",
    "                        validation_data = validation_set,\n",
    "                        validation_steps = 20\n",
    "                        );\n",
    "\n",
    "#Some Helpful Instructions:\n",
    "\n",
    "#finetune you network parameter in last by using low learning rate like 0.00001\n",
    "#classifier.save('resources/dogcat_model_bak.h5')\n",
    "#from tensorflow.keras.models import load_model\n",
    "#model = load_model('partial_trained1')\n",
    "#100 iteration w-5 ith learning rate 0.001 and after that 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9d272",
   "metadata": {},
   "source": [
    "Actually, I got this error trying to fit my model:\n",
    "\n",
    "<font color='red'>cannot identify image file _io.BytesIO object at 0x000001E97F9D55E0 </font>\n",
    "\n",
    "which indicates there are some corrupted files in the dataset. So, I ran the code below for each one of my directories with images; and deleted the corrupted file. If this was your case too, you'll need to create datasets again, since the corrupted files are still enlisted in those datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd13796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "image_dirs = ['./Pets/train/Cat/','./Pets/test/Cat/', './Pets/validation/Cat/', './Pets/train/Dog/',\n",
    "                 './Pets/test/Dog/','./Pets/validation/Dog/']\n",
    "\n",
    "for dirs in image_dirs:\n",
    "    path = Path(dirs).rglob(\"*.jpg\")\n",
    "    for img_p in path:\n",
    "        try:\n",
    "            img = PIL.Image.open(img_p)\n",
    "        except PIL.UnidentifiedImageError:\n",
    "            print(img_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca13bc0",
   "metadata": {},
   "source": [
    "To tune the model further, we can train it again on top of the current tuned parameters. To achieve a more accurate model, we would reduce the learning rate. Although this increases the training time, it takes smaller steps toward the optimal point, more likely to achieve a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ba20ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 48s 119ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 1.3727 - val_accuracy: 0.8391\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 1.3610 - val_accuracy: 0.8438\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 1.4736 - val_accuracy: 0.8281\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.2846 - val_accuracy: 0.8422\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 1.3239 - val_accuracy: 0.8484\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 1.3687 - val_accuracy: 0.8375\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 1.2728 - val_accuracy: 0.8484\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 1.3198 - val_accuracy: 0.8469\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 1.2837 - val_accuracy: 0.8562\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 1.2938 - val_accuracy: 0.8469\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.4130 - val_accuracy: 0.8406\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 1.2297 - val_accuracy: 0.8578\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.3464 - val_accuracy: 0.8453\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 1.2876 - val_accuracy: 0.8594\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 1.4909 - val_accuracy: 0.8422\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 1.3027 - val_accuracy: 0.8547\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 1.2793 - val_accuracy: 0.8531\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 1.5232 - val_accuracy: 0.8328\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.4360 - val_accuracy: 0.8469\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 58s 144ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 1.3300 - val_accuracy: 0.8516\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.1526 - val_accuracy: 0.8656\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.3348 - val_accuracy: 0.8469\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.3155 - val_accuracy: 0.8516\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 1.3362 - val_accuracy: 0.8594\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 1.4102 - val_accuracy: 0.8453\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.3398 - val_accuracy: 0.8562\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 1.3849 - val_accuracy: 0.8500\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.3715 - val_accuracy: 0.8516\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.3993 - val_accuracy: 0.8438\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.5022 - val_accuracy: 0.8406\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.3149 - val_accuracy: 0.8562\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.5126 - val_accuracy: 0.8359\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 53s 134ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.6690 - val_accuracy: 0.8281\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.4686 - val_accuracy: 0.8438\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.5670 - val_accuracy: 0.8438\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 1.5013 - val_accuracy: 0.8422\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 1.4396 - val_accuracy: 0.8375\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 1.3750 - val_accuracy: 0.8516\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 1.5607 - val_accuracy: 0.8375\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 1.5387 - val_accuracy: 0.8516\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.3811 - val_accuracy: 0.8547\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.4096 - val_accuracy: 0.8562\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.1847 - val_accuracy: 0.8719\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.4404 - val_accuracy: 0.8484\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 1.5185 - val_accuracy: 0.8516\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.5624 - val_accuracy: 0.8453\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.5733 - val_accuracy: 0.8406\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 1.5209 - val_accuracy: 0.8531\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.6140 - val_accuracy: 0.8375\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.5619 - val_accuracy: 0.8438\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 1.5589 - val_accuracy: 0.8484\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.4221 - val_accuracy: 0.8531\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.4860 - val_accuracy: 0.8516\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.5211 - val_accuracy: 0.8500\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.4898 - val_accuracy: 0.8609\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.4567 - val_accuracy: 0.8609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.2918 - val_accuracy: 0.8687\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.3737 - val_accuracy: 0.8625\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 1.5846 - val_accuracy: 0.8422\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.5328 - val_accuracy: 0.8484\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 1.6316 - val_accuracy: 0.8438\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.7482 - val_accuracy: 0.8344\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 6.4301e-04 - accuracy: 0.9998 - val_loss: 1.7101 - val_accuracy: 0.8328\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 7.9939e-04 - accuracy: 0.9997 - val_loss: 1.5405 - val_accuracy: 0.8500\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 4.6122e-04 - accuracy: 0.9998 - val_loss: 1.7456 - val_accuracy: 0.8422\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.9172 - val_accuracy: 0.8297\n",
      "Epoch 67/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.7595 - val_accuracy: 0.8406\n",
      "Epoch 68/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.4842 - val_accuracy: 0.8562\n",
      "Epoch 69/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 1.6647 - val_accuracy: 0.8484\n",
      "Epoch 70/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.4952 - val_accuracy: 0.8578\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.7714 - val_accuracy: 0.8375\n",
      "Epoch 72/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.6949 - val_accuracy: 0.8484\n",
      "Epoch 73/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.6163 - val_accuracy: 0.8484\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.5178 - val_accuracy: 0.8516\n",
      "Epoch 75/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 8.9770e-04 - accuracy: 0.9997 - val_loss: 1.5201 - val_accuracy: 0.8578\n",
      "Epoch 76/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 9.7488e-04 - accuracy: 0.9996 - val_loss: 1.7381 - val_accuracy: 0.8422\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 9.1487e-04 - accuracy: 0.9996 - val_loss: 1.7565 - val_accuracy: 0.8422\n",
      "Epoch 78/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.6414 - val_accuracy: 0.8422\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 5.5605e-04 - accuracy: 0.9998 - val_loss: 1.4660 - val_accuracy: 0.8562\n",
      "Epoch 80/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 1.7200 - val_accuracy: 0.8422\n",
      "Epoch 81/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.6940 - val_accuracy: 0.8531\n",
      "Epoch 82/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 9.7390e-04 - accuracy: 0.9996 - val_loss: 1.5850 - val_accuracy: 0.8594\n",
      "Epoch 83/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.5794 - val_accuracy: 0.8547\n",
      "Epoch 84/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 6.0746e-04 - accuracy: 0.9999 - val_loss: 1.7177 - val_accuracy: 0.8469\n",
      "Epoch 85/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 8.5773e-04 - accuracy: 0.9996 - val_loss: 1.5826 - val_accuracy: 0.8531\n",
      "Epoch 86/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.5085 - val_accuracy: 0.8703\n",
      "Epoch 87/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 8.6554e-04 - accuracy: 0.9996 - val_loss: 1.5443 - val_accuracy: 0.8594\n",
      "Epoch 88/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 8.0642e-04 - accuracy: 0.9997 - val_loss: 1.5218 - val_accuracy: 0.8531\n",
      "Epoch 89/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 4.6184e-04 - accuracy: 0.9998 - val_loss: 1.4654 - val_accuracy: 0.8656\n",
      "Epoch 90/200\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.9061 - val_accuracy: 0.8313\n",
      "Epoch 91/200\n",
      "400/400 [==============================] - 53s 133ms/step - loss: 6.8320e-04 - accuracy: 0.9998 - val_loss: 1.6357 - val_accuracy: 0.8469\n",
      "Epoch 92/200\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.6202 - val_accuracy: 0.8547\n",
      "Epoch 93/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 5.8581e-04 - accuracy: 0.9998 - val_loss: 1.8210 - val_accuracy: 0.8391\n",
      "Epoch 94/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 1.6608 - val_accuracy: 0.8484\n",
      "Epoch 95/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 8.6713e-04 - accuracy: 0.9996 - val_loss: 1.7931 - val_accuracy: 0.8453\n",
      "Epoch 96/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 1.6050 - val_accuracy: 0.8609\n",
      "Epoch 97/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.6463 - val_accuracy: 0.8484\n",
      "Epoch 98/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 1.6541 - val_accuracy: 0.8438\n",
      "Epoch 99/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.7204 - val_accuracy: 0.8438\n",
      "Epoch 100/200\n",
      "400/400 [==============================] - 55s 136ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.7196 - val_accuracy: 0.8406\n",
      "Epoch 101/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 1.7325 - val_accuracy: 0.8375\n",
      "Epoch 102/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 7.7393e-04 - accuracy: 0.9997 - val_loss: 1.8562 - val_accuracy: 0.8344\n",
      "Epoch 103/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 8.0021e-04 - accuracy: 0.9997 - val_loss: 1.5102 - val_accuracy: 0.8578\n",
      "Epoch 104/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.3682 - val_accuracy: 0.8672\n",
      "Epoch 105/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 8.0140e-04 - accuracy: 0.9998 - val_loss: 1.5395 - val_accuracy: 0.8578\n",
      "Epoch 106/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 5.0565e-04 - accuracy: 0.9998 - val_loss: 1.7028 - val_accuracy: 0.8516\n",
      "Epoch 107/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 2.5156e-04 - accuracy: 1.0000 - val_loss: 1.7202 - val_accuracy: 0.8516\n",
      "Epoch 108/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 6.0740e-04 - accuracy: 0.9998 - val_loss: 1.7580 - val_accuracy: 0.8406\n",
      "Epoch 109/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 5.0930e-04 - accuracy: 0.9998 - val_loss: 2.0354 - val_accuracy: 0.8281\n",
      "Epoch 110/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 7.8657e-04 - accuracy: 0.9995 - val_loss: 1.6635 - val_accuracy: 0.8469\n",
      "Epoch 111/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 8.8817e-04 - accuracy: 0.9997 - val_loss: 1.6192 - val_accuracy: 0.8594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.7658 - val_accuracy: 0.8547\n",
      "Epoch 113/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 1.7050 - val_accuracy: 0.8562\n",
      "Epoch 114/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.6688 - val_accuracy: 0.8609\n",
      "Epoch 115/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 1.8888 - val_accuracy: 0.8422\n",
      "Epoch 116/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 2.3830e-04 - accuracy: 0.9999 - val_loss: 1.7005 - val_accuracy: 0.8516\n",
      "Epoch 117/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 7.4964e-04 - accuracy: 0.9998 - val_loss: 1.4173 - val_accuracy: 0.8734\n",
      "Epoch 118/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 5.1699e-04 - accuracy: 0.9998 - val_loss: 1.6222 - val_accuracy: 0.8641\n",
      "Epoch 119/200\n",
      "400/400 [==============================] - 55s 138ms/step - loss: 9.3563e-04 - accuracy: 0.9997 - val_loss: 1.6473 - val_accuracy: 0.8578\n",
      "Epoch 120/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 7.7312e-04 - accuracy: 0.9998 - val_loss: 1.7999 - val_accuracy: 0.8469\n",
      "Epoch 121/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.5833 - val_accuracy: 0.8625\n",
      "Epoch 122/200\n",
      "400/400 [==============================] - 55s 137ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 1.6375 - val_accuracy: 0.8484\n",
      "Epoch 123/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.7149 - val_accuracy: 0.8484\n",
      "Epoch 124/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 7.0297e-04 - accuracy: 0.9998 - val_loss: 1.5679 - val_accuracy: 0.8625\n",
      "Epoch 125/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 5.6368e-04 - accuracy: 0.9998 - val_loss: 1.7594 - val_accuracy: 0.8422\n",
      "Epoch 126/200\n",
      "400/400 [==============================] - 54s 135ms/step - loss: 8.2395e-04 - accuracy: 0.9996 - val_loss: 1.4495 - val_accuracy: 0.8703\n",
      "Epoch 127/200\n",
      "400/400 [==============================] - 56s 139ms/step - loss: 5.3658e-04 - accuracy: 0.9997 - val_loss: 1.6304 - val_accuracy: 0.8547\n",
      "Epoch 128/200\n",
      "400/400 [==============================] - 55s 138ms/step - loss: 4.7615e-04 - accuracy: 0.9998 - val_loss: 1.6211 - val_accuracy: 0.8562\n",
      "Epoch 129/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 7.2477e-04 - accuracy: 0.9998 - val_loss: 1.6483 - val_accuracy: 0.8453\n",
      "Epoch 130/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 3.4813e-04 - accuracy: 0.9999 - val_loss: 1.6789 - val_accuracy: 0.8484\n",
      "Epoch 131/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 3.9730e-04 - accuracy: 0.9998 - val_loss: 2.0543 - val_accuracy: 0.8266\n",
      "Epoch 132/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 1.6475 - val_accuracy: 0.8516\n",
      "Epoch 133/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.0782 - val_accuracy: 0.8375\n",
      "Epoch 134/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 7.8871e-04 - accuracy: 0.9998 - val_loss: 1.6996 - val_accuracy: 0.8562\n",
      "Epoch 135/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.5779 - val_accuracy: 0.8578\n",
      "Epoch 136/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 4.8075e-04 - accuracy: 0.9998 - val_loss: 1.5449 - val_accuracy: 0.8625\n",
      "Epoch 137/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 5.1946e-04 - accuracy: 0.9998 - val_loss: 1.7219 - val_accuracy: 0.8516\n",
      "Epoch 138/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 1.9459e-04 - accuracy: 1.0000 - val_loss: 1.8715 - val_accuracy: 0.8422\n",
      "Epoch 139/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 6.2053e-04 - accuracy: 0.9998 - val_loss: 1.7573 - val_accuracy: 0.8469\n",
      "Epoch 140/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 5.6162e-04 - accuracy: 0.9998 - val_loss: 1.4964 - val_accuracy: 0.8687\n",
      "Epoch 141/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.9340 - val_accuracy: 0.8438\n",
      "Epoch 142/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 3.1726e-04 - accuracy: 0.9999 - val_loss: 1.7523 - val_accuracy: 0.8547\n",
      "Epoch 143/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 5.2725e-04 - accuracy: 0.9997 - val_loss: 1.7755 - val_accuracy: 0.8438\n",
      "Epoch 144/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 7.3465e-04 - accuracy: 0.9997 - val_loss: 2.0651 - val_accuracy: 0.8281\n",
      "Epoch 145/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.5881 - val_accuracy: 0.8578\n",
      "Epoch 146/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 5.3544e-04 - accuracy: 0.9999 - val_loss: 1.8028 - val_accuracy: 0.8547\n",
      "Epoch 147/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 2.9220e-04 - accuracy: 0.9999 - val_loss: 1.8197 - val_accuracy: 0.8516\n",
      "Epoch 148/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 6.0205e-04 - accuracy: 0.9998 - val_loss: 1.8091 - val_accuracy: 0.8562\n",
      "Epoch 149/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 1.9843 - val_accuracy: 0.8313\n",
      "Epoch 150/200\n",
      "400/400 [==============================] - 58s 145ms/step - loss: 4.6940e-04 - accuracy: 0.9999 - val_loss: 1.6023 - val_accuracy: 0.8594\n",
      "Epoch 151/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 8.7241e-04 - accuracy: 0.9998 - val_loss: 1.7956 - val_accuracy: 0.8453\n",
      "Epoch 152/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.3966 - val_accuracy: 0.8781\n",
      "Epoch 153/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.6611 - val_accuracy: 0.8500\n",
      "Epoch 154/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 3.3512e-04 - accuracy: 0.9999 - val_loss: 1.8206 - val_accuracy: 0.8438\n",
      "Epoch 155/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 3.5993e-04 - accuracy: 0.9999 - val_loss: 1.6885 - val_accuracy: 0.8547\n",
      "Epoch 156/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 4.2589e-04 - accuracy: 0.9998 - val_loss: 1.7547 - val_accuracy: 0.8547\n",
      "Epoch 157/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 8.0968e-04 - accuracy: 0.9998 - val_loss: 1.4945 - val_accuracy: 0.8594\n",
      "Epoch 158/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 3.4474e-04 - accuracy: 0.9999 - val_loss: 1.7138 - val_accuracy: 0.8531\n",
      "Epoch 159/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.0744 - val_accuracy: 0.8250\n",
      "Epoch 160/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.6638 - val_accuracy: 0.8578\n",
      "Epoch 161/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 7.0867e-04 - accuracy: 0.9998 - val_loss: 1.8835 - val_accuracy: 0.8500\n",
      "Epoch 162/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 7.2817e-04 - accuracy: 0.9998 - val_loss: 1.9584 - val_accuracy: 0.8391\n",
      "Epoch 163/200\n",
      "400/400 [==============================] - 57s 141ms/step - loss: 6.5365e-04 - accuracy: 0.9998 - val_loss: 1.7567 - val_accuracy: 0.8484\n",
      "Epoch 164/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 7.2984e-04 - accuracy: 0.9997 - val_loss: 1.9607 - val_accuracy: 0.8516\n",
      "Epoch 165/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 3.5856e-04 - accuracy: 0.9999 - val_loss: 1.7673 - val_accuracy: 0.8531\n",
      "Epoch 166/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 3.9017e-04 - accuracy: 0.9999 - val_loss: 1.7871 - val_accuracy: 0.8516\n",
      "Epoch 167/200\n",
      "400/400 [==============================] - 56s 141ms/step - loss: 3.6202e-04 - accuracy: 0.9999 - val_loss: 2.1457 - val_accuracy: 0.8297\n",
      "Epoch 168/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.6857 - val_accuracy: 0.8578\n",
      "Epoch 169/200\n",
      "400/400 [==============================] - 55s 139ms/step - loss: 7.5343e-04 - accuracy: 0.9997 - val_loss: 1.7643 - val_accuracy: 0.8500\n",
      "Epoch 170/200\n",
      "400/400 [==============================] - 55s 138ms/step - loss: 3.8310e-04 - accuracy: 0.9998 - val_loss: 2.0572 - val_accuracy: 0.8438\n",
      "Epoch 171/200\n",
      "400/400 [==============================] - 55s 138ms/step - loss: 6.3724e-04 - accuracy: 0.9996 - val_loss: 1.6642 - val_accuracy: 0.8625\n",
      "Epoch 172/200\n",
      "400/400 [==============================] - 56s 139ms/step - loss: 3.2613e-04 - accuracy: 0.9999 - val_loss: 1.8453 - val_accuracy: 0.8516\n",
      "Epoch 173/200\n",
      "400/400 [==============================] - 56s 139ms/step - loss: 6.4841e-04 - accuracy: 0.9998 - val_loss: 1.8712 - val_accuracy: 0.8484\n",
      "Epoch 174/200\n",
      "400/400 [==============================] - 56s 139ms/step - loss: 5.9887e-04 - accuracy: 0.9998 - val_loss: 1.9919 - val_accuracy: 0.8375\n",
      "Epoch 175/200\n",
      "400/400 [==============================] - 56s 140ms/step - loss: 7.3356e-04 - accuracy: 0.9998 - val_loss: 1.8154 - val_accuracy: 0.8500\n",
      "Epoch 176/200\n",
      "400/400 [==============================] - 58s 144ms/step - loss: 2.8839e-04 - accuracy: 1.0000 - val_loss: 1.7493 - val_accuracy: 0.8531\n",
      "Epoch 177/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 2.7193e-04 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.8562\n",
      "Epoch 178/200\n",
      "400/400 [==============================] - 58s 144ms/step - loss: 3.5292e-04 - accuracy: 0.9999 - val_loss: 1.8858 - val_accuracy: 0.8406\n",
      "Epoch 179/200\n",
      "400/400 [==============================] - 59s 148ms/step - loss: 6.7752e-04 - accuracy: 0.9998 - val_loss: 1.9322 - val_accuracy: 0.8422\n",
      "Epoch 180/200\n",
      "400/400 [==============================] - 54s 136ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 1.5833 - val_accuracy: 0.8625\n",
      "Epoch 181/200\n",
      "400/400 [==============================] - 59s 148ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.7062 - val_accuracy: 0.8578\n",
      "Epoch 182/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 8.8852e-04 - accuracy: 0.9998 - val_loss: 1.8510 - val_accuracy: 0.8531\n",
      "Epoch 183/200\n",
      "400/400 [==============================] - 58s 145ms/step - loss: 3.6002e-04 - accuracy: 0.9998 - val_loss: 1.8219 - val_accuracy: 0.8500\n",
      "Epoch 184/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 3.5382e-04 - accuracy: 0.9998 - val_loss: 1.8054 - val_accuracy: 0.8484\n",
      "Epoch 185/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 4.2942e-04 - accuracy: 0.9998 - val_loss: 1.6820 - val_accuracy: 0.8625\n",
      "Epoch 186/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 7.7371e-04 - accuracy: 0.9997 - val_loss: 2.0095 - val_accuracy: 0.8328\n",
      "Epoch 187/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 2.8065e-04 - accuracy: 0.9999 - val_loss: 1.9403 - val_accuracy: 0.8391\n",
      "Epoch 188/200\n",
      "400/400 [==============================] - 59s 148ms/step - loss: 2.3122e-04 - accuracy: 0.9999 - val_loss: 1.8183 - val_accuracy: 0.8453\n",
      "Epoch 189/200\n",
      "400/400 [==============================] - 55s 139ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.8135 - val_accuracy: 0.8406\n",
      "Epoch 190/200\n",
      "400/400 [==============================] - 56s 139ms/step - loss: 2.1352e-04 - accuracy: 1.0000 - val_loss: 2.0208 - val_accuracy: 0.8297\n",
      "Epoch 191/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 2.5457e-04 - accuracy: 1.0000 - val_loss: 1.8106 - val_accuracy: 0.8531\n",
      "Epoch 192/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 4.7030e-04 - accuracy: 0.9998 - val_loss: 1.5687 - val_accuracy: 0.8656\n",
      "Epoch 193/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 3.0463e-04 - accuracy: 0.9999 - val_loss: 1.6353 - val_accuracy: 0.8609\n",
      "Epoch 194/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.7753 - val_accuracy: 0.8531\n",
      "Epoch 195/200\n",
      "400/400 [==============================] - 58s 145ms/step - loss: 4.7077e-04 - accuracy: 0.9998 - val_loss: 1.7830 - val_accuracy: 0.8531\n",
      "Epoch 196/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 4.7047e-04 - accuracy: 0.9999 - val_loss: 1.7145 - val_accuracy: 0.8578\n",
      "Epoch 197/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 6.8130e-04 - accuracy: 0.9998 - val_loss: 1.5978 - val_accuracy: 0.8656\n",
      "Epoch 198/200\n",
      "400/400 [==============================] - 57s 143ms/step - loss: 6.5742e-04 - accuracy: 0.9997 - val_loss: 1.6157 - val_accuracy: 0.8562\n",
      "Epoch 199/200\n",
      "400/400 [==============================] - 58s 144ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.9042 - val_accuracy: 0.8344\n",
      "Epoch 200/200\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 6.3381e-04 - accuracy: 0.9997 - val_loss: 2.1037 - val_accuracy: 0.8266\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "classifier.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "classifier.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Training 2\n",
    "history = classifier.fit(train_set,\n",
    "                        steps_per_epoch=400, \n",
    "                        epochs = 200,\n",
    "                        validation_data = validation_set,\n",
    "                        validation_steps = 20\n",
    "                        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd58815",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('./dog_n_cat_model_2.h5')\n",
    "\n",
    "# classifier = load_model('./dog_n_cat_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e061e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predict</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat\\0.jpg</td>\n",
       "      <td>0.67719</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat\\10.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cat\\10005.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat\\10009.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cat\\10010.jpg</td>\n",
       "      <td>0.80164</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cat\\10011.jpg</td>\n",
       "      <td>0.60874</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cat\\10012.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cat\\10014.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cat\\10027.jpg</td>\n",
       "      <td>0.08360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cat\\10029.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cat\\1003.jpg</td>\n",
       "      <td>0.81155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cat\\10032.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cat\\10038.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cat\\10041.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cat\\10050.jpg</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cat\\10051.jpg</td>\n",
       "      <td>0.01673</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cat\\10053.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cat\\10060.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cat\\10063.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cat\\10064.jpg</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  predict  y  y_pred\n",
       "0       Cat\\0.jpg  0.67719  0       1\n",
       "1      Cat\\10.jpg  0.00000  0       0\n",
       "2   Cat\\10005.jpg  0.00000  0       0\n",
       "3   Cat\\10009.jpg  0.00000  0       0\n",
       "4   Cat\\10010.jpg  0.80164  0       1\n",
       "5   Cat\\10011.jpg  0.60874  0       1\n",
       "6   Cat\\10012.jpg  0.00000  0       0\n",
       "7   Cat\\10014.jpg  0.00000  0       0\n",
       "8   Cat\\10027.jpg  0.08360  0       0\n",
       "9   Cat\\10029.jpg  0.00000  0       0\n",
       "10   Cat\\1003.jpg  0.81155  0       1\n",
       "11  Cat\\10032.jpg  0.00000  0       0\n",
       "12  Cat\\10038.jpg  0.00000  0       0\n",
       "13  Cat\\10041.jpg  0.00000  0       0\n",
       "14  Cat\\10050.jpg  0.00007  0       0\n",
       "15  Cat\\10051.jpg  0.01673  0       0\n",
       "16  Cat\\10053.jpg  0.00000  0       0\n",
       "17  Cat\\10060.jpg  0.00000  0       0\n",
       "18  Cat\\10063.jpg  0.00000  0       0\n",
       "19  Cat\\10064.jpg  0.00120  0       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import tensorflow\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "# Testing the model on test_set\n",
    "test_set.reset\n",
    "ytesthat = classifier.predict_generator(test_set)\n",
    "df = pd.DataFrame({\n",
    "    'filename':test_set.filenames,\n",
    "    'predict':ytesthat[:,0],\n",
    "    'y':test_set.classes\n",
    "})\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "df['y_pred'] = df['predict']>0.5\n",
    "df.y_pred = df.y_pred.astype(int)\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c97e13ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total misclassified image from 5000 Validation images : 666\n"
     ]
    }
   ],
   "source": [
    "misclassified = df[df['y']!=df['y_pred']]\n",
    "print('Total misclassified image from 5000 Validation images : %d'%misclassified['y'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84317031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction of test set\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(df.y,df.y_pred)\n",
    "sns.heatmap(conf_matrix,cmap=\"YlGnBu\",annot=True,fmt='g');\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b750b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy  : 99.98%     Training loss  : 0.000726\n",
      "Validation Accuracy: 86.68%     Validation loss: 1.485540\n",
      "Test Accuracy: 86.68%           Test loss: 1.509541\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# Model Accuracy\n",
    "x1 = classifier.evaluate_generator(train_set)\n",
    "x2 = classifier.evaluate_generator(validation_set)\n",
    "x3 = classifier.evaluate_generator(test_set)\n",
    "print('Training Accuracy  : %1.2f%%     Training loss  : %1.6f'%(x1[1]*100,x1[0]))\n",
    "print('Validation Accuracy: %1.2f%%     Validation loss: %1.6f'%(x2[1]*100,x2[0]))\n",
    "print('Test Accuracy: %1.2f%%           Test loss: %1.6f'%(x3[1]*100,x3[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63460930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
